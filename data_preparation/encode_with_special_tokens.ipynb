{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1178792b",
   "metadata": {},
   "source": [
    "# Load the ChessExplained dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e422ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"../data/ChessExplained_2500k_qwen3.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc42894",
   "metadata": {},
   "source": [
    "# Encode chess position\n",
    "We're using special tokens for encoding the chess position, since FEN encoding isn't good for an LLM's tokenizer with characters getting merged. \n",
    "\n",
    "Ascii representation will not have the character merge issue, but will be inefficient compared to a special encoding which uses significantly lower number of tokens. We found this reduces illegal moves while training, and much faster to train due to fewer input tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb89d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a1><White_Rook><b1><White_Knight><c1><White_Bishop><d1><White_Queen><e1><White_King><f1><White_Bishop><g1><White_Knight><h1><White_Rook><a2><White_Pawn><b2><White_Pawn><c2><White_Pawn><d2><White_Pawn><e2><blank><f2><White_Pawn><g2><White_Pawn><h2><White_Pawn><a3><blank><b3><blank><c3><blank><d3><blank><e3><White_Pawn><f3><blank><g3><blank><h3><blank><a4><blank><b4><blank><c4><blank><d4><blank><e4><blank><f4><blank><g4><blank><h4><blank><a5><blank><b5><blank><c5><blank><d5><blank><e5><Black_Pawn><f5><blank><g5><blank><h5><blank><a6><blank><b6><blank><c6><blank><d6><blank><e6><blank><f6><blank><g6><blank><h6><blank><a7><Black_Pawn><b7><Black_Pawn><c7><Black_Pawn><d7><Black_Pawn><e7><blank><f7><Black_Pawn><g7><Black_Pawn><h7><Black_Pawn><a8><Black_Rook><b8><Black_Knight><c8><Black_Bishop><d8><Black_Queen><e8><Black_King><f8><Black_Bishop><g8><Black_Knight><h8><Black_Rook>|White|KQkq|-|0|2|<g1><h3> <g1><f3> <g1><e2> <f1><a6> <f1><b5> <f1><c4> <f1><d3> <f1><e2> <e1><e2> <d1><h5> <d1><g4> <d1><f3> <d1><e2> <b1><c3> <b1><a3> <e3><e4> <h2><h3> <g2><g3> <f2><f3> <d2><d3> <c2><c3> <b2><b3> <a2><a3> <h2><h4> <g2><g4> <f2><f4> <d2><d4> <c2><c4> <b2><b4> <a2><a4>\n"
     ]
    }
   ],
   "source": [
    "import chess\n",
    "\n",
    "def encode_legal_moves(board):\n",
    "    \"\"\"Encode legal moves as special token sequence.\"\"\"\n",
    "    color = 'White' if board.turn == chess.WHITE else 'Black'\n",
    "    promo_map = {chess.QUEEN: f'<{color}_Queen>', chess.ROOK: f'<{color}_Rook>', \n",
    "                 chess.BISHOP: f'<{color}_Bishop>', chess.KNIGHT: f'<{color}_Knight>'}\n",
    "    \n",
    "    moves = [f\"<{chess.square_name(m.from_square)}><{chess.square_name(m.to_square)}>\"\n",
    "             + (promo_map[m.promotion] if m.promotion else \"\")\n",
    "             for m in board.legal_moves]\n",
    "    \n",
    "    return \" \".join(moves)\n",
    "\n",
    "def piece_to_token(piece):\n",
    "    if piece is None:\n",
    "        return '<blank>'\n",
    "    \n",
    "    piece_map = {\n",
    "        (chess.PAWN, chess.WHITE): '<White_Pawn>',\n",
    "        (chess.KNIGHT, chess.WHITE): '<White_Knight>',\n",
    "        (chess.BISHOP, chess.WHITE): '<White_Bishop>',\n",
    "        (chess.ROOK, chess.WHITE): '<White_Rook>',\n",
    "        (chess.QUEEN, chess.WHITE): '<White_Queen>',\n",
    "        (chess.KING, chess.WHITE): '<White_King>',\n",
    "        (chess.PAWN, chess.BLACK): '<Black_Pawn>',\n",
    "        (chess.KNIGHT, chess.BLACK): '<Black_Knight>',\n",
    "        (chess.BISHOP, chess.BLACK): '<Black_Bishop>',\n",
    "        (chess.ROOK, chess.BLACK): '<Black_Rook>',\n",
    "        (chess.QUEEN, chess.BLACK): '<Black_Queen>',\n",
    "        (chess.KING, chess.BLACK): '<Black_King>',\n",
    "    }\n",
    "    \n",
    "    return piece_map[(piece.piece_type, piece.color)]\n",
    "\n",
    "def encode_board_position(fen):\n",
    "    \"\"\"Encode FEN to special token sequence.\"\"\"\n",
    "    board = chess.Board(fen)\n",
    "    \n",
    "    # Board tokens\n",
    "    tokens = [f\"<{chess.square_name(sq)}>{piece_to_token(board.piece_at(sq))}\" \n",
    "              for sq in chess.SQUARES]\n",
    "    \n",
    "    # Metadata\n",
    "    parts = fen.split()\n",
    "    side = \"White\" if parts[1] == 'w' else \"Black\"\n",
    "    other_info = f\"{parts[2]}|{parts[3]}|{parts[4]}|{parts[5]}\"\n",
    "    legal_moves = encode_legal_moves(board)\n",
    "\n",
    "    return \"\".join(tokens) + f\"|{side}|{other_info}|{legal_moves}\"\n",
    "\n",
    "fen = \"rnbqkbnr/pppp1ppp/8/4p3/8/4P3/PPPP1PPP/RNBQKBNR w KQkq - 0 2\"\n",
    "# fen = \"4k3/P7/8/8/8/8/8/4K3 w - - 0 1\"\n",
    "seq = encode_board_position(fen)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17694c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_messages(row, disable_thinking=False):\n",
    "    \"\"\"Create chat messages from row data.\"\"\"\n",
    "    fen = row['fen']\n",
    "    explanation = row['explanation'] if 'explanation' in row else \"\"\n",
    "    move = row['move']\n",
    "    \n",
    "    # User message with encoded board position\n",
    "    board_encoding = encode_board_position(fen)\n",
    "    user_msg = f\"<chess_position>{board_encoding}</chess_position>\"\n",
    "    \n",
    "    # Assistant message with thinking and move\n",
    "    move_tokens = f\"<uci_move>{move}</uci_move>\"\n",
    "    if disable_thinking:\n",
    "        assistant_msg = f\"{move_tokens}\"\n",
    "    else:\n",
    "        assistant_msg = f\"<think>\\n{explanation}\\n</think>\\n\\n{move_tokens}\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_msg}\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169da9c6",
   "metadata": {},
   "source": [
    "# Test Jinja2 encoding matches python\n",
    "The submission sysyem only uses Jinja2 to encode the position. If you use python to encode the dataset like the code above, ensure that the jinja2 template produces the same text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2fa491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jinja2 encoding matches Python encoding\n"
     ]
    }
   ],
   "source": [
    "import jinja2\n",
    "template = jinja2.Template(open('chess_encode_special_tokens.jinja').read())\n",
    "\n",
    "fen = df.loc[2, 'fen']\n",
    "legal_moves = chess.Board(fen).legal_moves\n",
    "legal_moves = ' '.join([m.uci() for m in legal_moves])\n",
    "prompt = f\"{fen}|{legal_moves}\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "orig_encoding = f\"<chess_position>{encode_board_position(fen)}</chess_position>\"\n",
    "jinja_rendered = template.render(FEN=fen, legal_moves_uci=legal_moves)\n",
    "assert jinja_rendered == orig_encoding\n",
    "print(\"Jinja2 encoding matches Python encoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1fcce",
   "metadata": {},
   "source": [
    "# Encoding example\n",
    "The below code is provided as an example if you want to use a different encoding structure.\n",
    "\n",
    "If encoding a large dataset, running Threads or Processes to speed things up may be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16afb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipam/miniconda3/envs/chesscomments/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "chess_tokenizer = AutoTokenizer.from_pretrained(\"chess_tokenizer_qwen3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6511d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "<chess_position><a1><blank><b1><blank><c1><White_King><d1><White_Rook><e1><blank><f1><blank><g1><blank><h1><blank><a2><blank><b2><blank><c2><White_Pawn><d2><White_Queen><e2><White_Bishop><f2><blank><g2><Black_Bishop><h2><blank><a3><blank><b3><White_Pawn><c3><blank><d3><blank><e3><blank><f3><blank><g3><Black_Queen><h3><Black_Pawn><a4><White_Pawn><b4><blank><c4><blank><d4><White_Pawn><e4><blank><f4><White_Pawn><g4><blank><h4><Black_Rook><a5><blank><b5><blank><c5><blank><d5><Black_Pawn><e5><White_Pawn><f5><blank><g5><blank><h5><blank><a6><Black_Pawn><b6><blank><c6><blank><d6><blank><e6><blank><f6><blank><g6><blank><h6><blank><a7><blank><b7><Black_Pawn><c7><Black_Pawn><d7><blank><e7><blank><f7><Black_Pawn><g7><Black_Pawn><h7><blank><a8><Black_Rook><b8><Black_Knight><c8><blank><d8><blank><e8><Black_King><f8><blank><g8><blank><h8><blank>|White|q|-|1|19|<e2><a6> <e2><h5> <e2><b5> <e2><g4> <e2><c4> <e2><f3> <e2><d3> <e2><f1> <d2><a5> <d2><b4> <d2><e3> <d2><d3> <d2><c3> <d2><e1> <d1><h1> <d1><g1> <d1><f1> <d1><e1> <c1><b2> <c1><b1> <e5><e6> <f4><f5> <a4><a5> <b3><b4> <c2><c3> <c2><c4></chess_position><|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "King to b2 helps White reposition the piece. So Kb2 is natural progression. White has a huge advantage.\n",
      "</think>\n",
      "\n",
      "<uci_move>c1b2</uci_move><|im_end|>\n",
      "\n",
      "275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Test on a small sample\n",
    "test_df = df.head(20).copy()\n",
    "test_df['messages'] = test_df.apply(lambda x: create_chat_messages(x, disable_thinking=False), axis=1)\n",
    "test_df['text'] = test_df['messages'].apply(lambda x: chess_tokenizer.apply_chat_template(x, tokenize=False))\n",
    "\n",
    "print(test_df['text'].iloc[10])\n",
    "print(len(chess_tokenizer.tokenize(test_df['text'].iloc[10])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chesscomments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
